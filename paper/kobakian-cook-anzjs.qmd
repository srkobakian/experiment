---
title: "Comparing the Effectiveness of the Choropleth Map with a Hexagon Tile Map for Communicating Patterns in Australian Spatial Statistics"
format:
  quarto-anzjs-pdf:
    keep-tex: true  
    shorttitle: "Automated Residual Plot Assessment"
    double-space: true
    line-numbers: true
date: today
date-format: "YYYY" # used to define volumeyear
author:
    - name: Stephanie Kobakian  
      email: stephanie.kobakian@gmail.com
      affiliation:
          - name: Queensland University of Technology
            department: Science and Engineering Faculty
            address: 2 George St, Brisbane, Australia
    - name: Dianne Cook
      email: dicook@monash.edu
      affiliation: 
          - name: Monash University
            department: Econometrics and Business Statistics Faculty
            address: 29 Ancora Imparo Way, Clayton, VIC 3800, Australia
keywords: ["data visualisation", "visual inference", "geospatial", "statistical graphics", "designed experiment"]
abstract: |
  The choropleth map is a common tool for communicating spatial distributions across geographic areas. However, the size of geographic units can distort interpretation, influencing how users perceive the distribution. A common alternative is the cartogram, which resizes areas based on population. Yet, in Australia, the stark disparities in geography and population make cartograms less suitable. This study explores the hexagon tile map as an alternative. We report results from a task-based experiment involving human participants, using the lineup protocol to assess how well hexagon tile maps and choropleths convey spatial patterns. Three spatial patterns were tested: one reflecting geography, with values increasing monotonically from the northwest to southeast of Australia, and two with clustered high concentrations. Results show that the hexagon tile map outperforms the choropleth map. These findings support the use of alternative map displays and suggest that hexagon tile maps are effective for visualising spatial distributions in heterogeneous regions.
bibliography: paper.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  error = FALSE, 
  message = FALSE,
  cache = FALSE,
  dpi = 300,
  out.width = "100%")
```

```{r libraries}
# Load Libraries
library(tidyverse)
library(readxl)
library(broom)
library(broom.mixed)
library(cowplot)
library(ggbeeswarm)
library(png)
library(grid)
library(lme4)
library(cartogram)
library(sugarbag)
library(sf)
library(ggstats)
library(emmeans)
library(ggthemes)
library(RColorBrewer)
library(knitr)
library(kableExtra)
library(patchwork)

options(knitr.kable.digits = "2")
```

```{r data}
trend_colors <- c(
  "NW-SE" = "#B2DF8A",
  "Three Cities" = "#A6CEE3",
  "All Cities" = "#1F78B4")
  
type_colors <- c(
  "Choro." = "#a8c0a8",#"#fcae91",
  "Hex." = "#BD852C")  #"#a50f15")

type2_colors <- c(
  "choropleth" = "#d95f02",#"#fcae91",
  "hexagon tile" = "#e7298a")  #"#a50f15")

detect_f_colors <- c(
  "No" = "#66C2A5",
  "Yes" = "#FC8D62")

detect_colors <- c(
  "Detected? No" = "#66C2A5",
  "Detected? Yes" = "#FC8D62")

  # Downloaded data
d <- read_xlsx("data/experiment-export.xlsx", sheet=2) |>
  filter(!is.na(contributor)) |>
  mutate(contributor = factor(contributor))

n_all_contributors <- d |> count(contributor, sort=TRUE) |> 
  summarise(n_contributors = length(contributor))
  
n_all_evals <- nrow(d)

# Check data set 
# Need to clean multiple entries, 48, 24
# remove duplicated entries due to submit button
d <- d |> group_by(group, contributor, image_name) |>
  slice(1) |> ungroup() |> 
  arrange(group, contributor, plot_order)

# Remove contributors who did not provide answers to most questions
keep <- d |> count(contributor, sort = TRUE) |> filter(n > 10)
d <- d |> 
  filter(contributor %in% keep$contributor) |>
  filter(contributor != "1234567890") # Testing id

# Remove contributors who did not provide any choices
# Or an insufficient amount of responses
bad_contribs <- d |> group_by(contributor) |> 
  #summarise(sum0 = sum(choice)) |> 
  summarise(n_zero = sum(if_else(choice == 0, 1, 0))) |>
  #filter(sum0 < 13) |> 
  filter(n_zero > 8) |>
  pull(contributor)

# Person is in list above
same_answer <- d |> group_by(contributor) |> 
  summarise(v = sd(choice))

# check range of choices
choice_range <- d |> group_by(contributor) |> summarise(m1 = min(choice), m2 = max(choice))

d <- d |> 
  filter(!(contributor %in% bad_contribs))

n_contributors <- d |> count(contributor, sort=TRUE) |> 
  summarise(n_contributors = length(contributor))

n_AB <- d |> count(contributor, group) |> count(group) 
n_gender <- d |> count(contributor, gender) |> count(gender)
n_educ <- d |> count(contributor, education) |> count(education)
n_age <- d |> count(contributor, age) |> count(age)
n_aus <- d |> count(contributor, australia) |> count(australia)

n_evals <- nrow(d)
  
d <- d |> mutate(certainty = factor(as.character(certainty),
  levels = c("1", "2", "3", "4","5"), ordered=TRUE))
```


```{r reps}
replicate <- tibble(image_name = c("aus_cities_12_geo.png", "aus_cities_12_hex.png", 
                                   "aus_cities_3_geo.png", "aus_cities_3_hex.png",
                                   "aus_cities_4_geo.png", "aus_cities_4_hex.png",
                                   "aus_cities_9_geo.png", "aus_cities_9_hex.png",
                                   "aus_nwse_2_geo.png", "aus_nwse_2_hex.png",
                                   "aus_nwse_3_geo.png", "aus_nwse_3_hex.png",
                                   "aus_nwse_5_geo.png", "aus_nwse_5_hex.png",
                                   "aus_nwse_6_geo.png", "aus_nwse_6_hex.png",
                                   "aus_three_12_geo.png", "aus_three_12_hex.png",
                                   "aus_three_5_geo.png", "aus_three_5_hex.png",
                                   "aus_three_8_geo.png", "aus_three_8_hex.png",
                                   "aus_three_9_geo.png", "aus_three_9_hex.png"),
                    replicate = c(1, 1, 2, 2, 3, 3, 4, 4, 
                                  1, 1, 2, 2, 3, 3, 4, 4,
                                  1, 1, 2, 2, 3, 3, 4, 4))
# Add rep info to data
d <- d |> left_join(replicate, by = "image_name")
```

```{r pdetection_group}
# Tidy for analysis
d <- d |> 
  separate(image_name, c("nothing", "trend", "location", "type", "extra"), remove = FALSE) |>
  select(-nothing, -extra) |>
  mutate(location = as.numeric(location), 
    # detect measures the accuracy of the choice
         detect = ifelse(location == choice, 1, 0)) |> 
  mutate(trend = case_when(
    trend == "nwse" ~ "NW-SE",
    trend == "cities" ~ "All Cities",
    trend == "three" ~ "Three Cities")) |> 
  mutate(trend = fct_relevel(trend,"All Cities","Three Cities", "NW-SE")) |> 
  mutate(type = case_when(
    type == "hex" ~"Hex.",
    TRUE~"Choro.")) |> 
    mutate(detect_f = factor(detect, levels = c(1, 0), labels = c("Detected? Yes", "Detected? No")))

plots <- d |> group_by(group, trend, type, location) |>
  # pdetect measures the aggregated accuracy of the choices
  summarise(pdetect = length(detect[detect == 1])/length(detect)) 
```

```{r makethyroidplots}
# Spatial polygons files sourced from: https://github.com/wfmackey/absmapsdata
load("data/sa22011.rda")
load("data/state2011.rda")

invthm <- theme_map() + 
  theme(
    panel.background = element_rect(fill = "black", colour = NA), 
    legend.background = element_rect(fill = "transparent", colour = NA),
    legend.key = element_rect(fill = "transparent", colour = NA),
    axis.text = element_blank()
  )

# function to allocate colours to regions
aus_colours <- function(sir_p50){
  value <- case_when(
    sir_p50 <  0.74 ~ "#33809d",
    sir_p50 >= 0.74 & sir_p50 < 0.98 ~ "#aec6c7",
    sir_p50 >= 0.98 & sir_p50 < 1.05 ~ "#fff4bc",
    sir_p50 >= 1.05 & sir_p50 < 1.45 ~ "#ff9a64",
    sir_p50 >= 1.45 ~ "#ff3500",
    TRUE ~ "#FFFFFF")
  return(value)
}

sa2 <- sa22011 |> 
  filter(!st_is_empty(geometry)) |> 
  filter(!state_name_2011 == "Other Territories") |> 
  filter(!sa2_name_2011 == "Lord Howe Island")

SIR <- read_csv("data/SIR Downloadable Data.csv") |> 
  filter(SA2_name %in% sa2$sa2_name_2011) |> 
  dplyr::select(Cancer_name, SA2_name, Sex_name, p50) |> 
  filter(Cancer_name == "Thyroid", Sex_name == "Females")
ERP <- read_csv("data/ERP.csv") |>
  filter(REGIONTYPE == "SA2", Time == 2011, Region %in% SIR$SA2_name) |> 
  dplyr::select(Region, Value)
# Alternative maps
# Join with sa2 sf object
sa2thyroid_ERP <- left_join(sa2, SIR, by = c("sa2_name_2011" = "SA2_name")) |>
  left_join(ERP |> 
              dplyr::select(Region, 
              Population = Value), by = c("sa2_name_2011"= "Region")) |> 
  filter(!st_is_empty(geometry))
sa2thyroid_ERP <- sa2thyroid_ERP |> 
  #filter(!is.na(Population)) |> 
  filter(!sa2_name_2011 == "Lord Howe Island") |> 
  mutate(SIR = map_chr(p50, aus_colours)) |> 
  st_as_sf() 

# Make choropleth
aus_ggchoro <- ggplot(sa2thyroid_ERP) + 
  geom_sf(aes(fill = SIR), size = 0.1) + 
  scale_fill_identity() + invthm +
  ggtitle("a. choropleth map")

# Make hexmap
if (!file.exists("data/aus_hexmap.rda")) {

## Check the projection uses long and lat
## Create centroids set
sa2centroids <- create_centroids(sa2, "sa2_name_2011")
## Create hexagon grid
# For speed, consider if the buffer distance beyond the centroids is necessary
grid <- create_grid(centroids = sa2centroids,
                    hex_size = 0.15,
                    buffer_dist = 4, verbose = TRUE)
## Allocate polygon centroids to hexagon grid points
# This is a time consuming process for a large data set
aus_hexmap <- allocate(
  centroids = sa2centroids,
  hex_grid = grid,
  sf_id = "sa2_name_2011",
  ## same column used in create_centroids
  hex_size = 0.15,
  hex_filter = 8,
  focal_points = capital_cities,
  width = 25,
  verbose = TRUE)
save(aus_hexmap, file = "data/aus_hexmap.rda") 
}

load("data/aus_hexmap.rda")

## Prepare to plot
fort_hex <- fortify_hexagon(data = aus_hexmap,
                            sf_id = "sa2_name_2011",
                            hex_size = 0.3) |> 
            left_join(sa2thyroid_ERP |>
            select(sa2_name_2011, SIR, p50))
fort_aus <- sa2thyroid_ERP |>
  fortify_sfc()
## Make a plot
aus_hexmap_plot <- ggplot() +
  geom_polygon(aes(x = long,  y = lat,  
        group = interaction(sa2_name_2011, polygon)),
               fill = "black",  colour = "darkgrey", 
               linewidth = 0.1, data = fort_aus) +
  geom_polygon(aes(x = long, y = lat, group = hex_id, 
                   fill = SIR), data = fort_hex) +
  scale_fill_identity() +
  invthm + coord_equal() +
  ggtitle("b. hexagon tile map")
```

# Introduction {#sec-introduction}

<!-- General: comparison of displays, motivate hexagon tile map, enough info to motivate aims -->
<!-- geographies on choropleth -->
This study compares the effectiveness of the spatial display, a hexagon tile map, against the standard, a choropleth map, for communicating information about disease statistics. The choropleth map is the traditional method for visualizing aggregated statistics across administrative boundaries. It works better for countries that have administrative areas that are relatively equally sized spatially, which is far from the situation in Australia. The hexagon tile map builds on existing displays, such as the cartogram, and tessellated hexagon displays. A hexagon tile map forgoes the familiar boundaries, in favour of representing each geographic unit as an equally sized hexagon, placed approximately in the correct spatial location.  It differs in the relaxed requirement to have connected hexagons, and allows sparsely located hexagons. This type of display may be generally useful for displaying government statistics spatially, and other spatial display purposes. The algorithm to construct a hexagon tile map is available in the R package sugarbag [@sugarbag]. 

The hexagon tile map was designed for Australia, motivated by a need to display spatial statistics for the Australian Cancer Atlas. None of the existing approaches for creating cartograms or hexagon tiling perform well for the Australian landscape, which has vast open spaces and concentrations of population in small regions clustered on the coastlines. 

The Australian Cancer Atlas [@atlas] is an online interactive web tool created to explore the burden of cancer on Australian communities. There are many cancer types to be explored individually or aggregated. The Australian Cancer Atlas allows users to explore the patterns in the distributions of cancer statistics over the geographic space of Australia. It uses a choropleth map display and diverging colour scheme to draw attention to relationships between neighbouring areas. The hexagon tile map may be a useful alternative display to enhance the atlas. 

The experiment was conducted using the lineup protocol, a visual inference procedure [@BCHLLSW09;@GIIV], that can be used to objectively test the effectiveness of the two displays [@GTPCCD]. A lineup embeds the data plot among a field of null data plots, and an independent observer is asked to select the most different plot. It was shown by @VVSIALM to be an effective way to conduct a hypothesis test where a plot is treated as a test statistic, and utilised for this purpose in numerous studies [@FFS;@Green2021;@LCTV]. If the data plot is selected it is analogous to a rejection of the null hypothesis (specifying no structure), and the observed data plot is unlikely to arise from the null scenario. The work of @VH2016 compares the lineup protocol to performance on standard tests of visual ability, concluding that participants' performance is related to general visual aptitude, to classification rather than spatial reasoning.

The paper is organised as follows. The next section discusses the background of geographic data display and visual inference procedures. @sec-methodology describes the methods for conducting the experiment and analysing the results. The results are summarised in the @sec-results, followed by a discussion about the broader implications for the use of this map style. 

# Background {#sec-background}

## Spatial data displays

<!-- foundation, tradition -->  
Spatial visualisations communicate the distribution of statistics over geographic landscapes. The choropleth map [@EI;@BCM] is a traditional display. It is used to present statistics that have been aggregated on geographic units. Creating a choropleth map involves drawing polygons representing the administrative boundaries, and filling with colour mapped to the value of the statistic. The choropleth map places the statistic in the context of the spatial domain, so that the reader can see whether there are spatial trends, clusters or anomalies. This is important for digesting disease patterns. If there is a linear trend it may imply a relationship between disease and geographic location. If there is a cluster, or an anomaly, there may be a localized outbreak of the disease. 

```{r liver, eval=FALSE, fig.height = 4, fig.width = 4, fig.cap = "A choropleth map of the smoothed average of liver cancer diagnoses for Australian males. The diverging colour scheme uses dark blue areas for much lower than average diagnoses, yellow areas with diagnoses around the Australian average, red shows diagnoses much higher than average. The hexagon tile map shows concentrations of higher than expected liver cancer rates in the cities of Melbourne and Sydney, which is not visible from the choropleth map.", results = "asis"}
ggdraw() +
  draw_plot(rasterGrob(readPNG("figures/aus_liver_m.png")))
```

```{r liver-hex, eval=FALSE, fig.height = 4, fig.width = 4, fig.cap = "A hexagon tile map of the smoothed average of liver cancer diagnoses for Australian males. The diverging colour scheme uses dark blue areas for much lower than average diagnoses, yellow areas with diagnoses around the Australian average, red shows diagnoses much higher than average. The hexagon tile map shows concentrations of higher than expected liver cancer rates in the cities of Melbourne and Sydney, which is not visible from the choropleth map.", results = "asis"}

ggdraw() +
  draw_plot(rasterGrob(readPNG("figures/aus_liver_m_hex.png")))
```

```{r}
#| label: fig-thyroid
#| fig-cap: "Thyroid cancer incidence among females across the Statistical Areas of Australia at Level 2, displayed using a choropleth map (a) and a hexagon tile map (b). Blue indicates lower than average, and red indicates higher than average incidence. The choropleth map suggests high incidence is clustered on the east coast but misses the high incidence in Perth and a few locations in inner Melbourne visible in the hexagon tile map."
#| out-width: 100%
#| fig-width: 8
#| fig-height: 3
aus_ggchoro + aus_hexmap_plot + plot_layout(ncol=2)
```

The choropleth map is an effective spatial display if the size of the geographic units is relatively uniform. This is not the case for most countries. Size heterogeneity in administrative units is particularly extreme in Australia: most of the landscape of Australia is sparsely settled, with the population densely clustered into the narrow coastal strips. @fig-thyroid shows the choropleth map of thyroid cancer incidence rates in Australia. The choropleth map focuses attention on the geography, and for heterogeneously sized areas it presents a biased view of the population related distribution of the statistic [@CBATCC]. *Land does not get cancer, people do* -- a more effective way to communicate the spatial distributions of cancer statistics is needed (sentiment motivated by @monmonier2018how). 

<!-- Cartogram -->
A cartogram is a general solution for adequately displaying a population-based statistic. It transforms the geographic map base to reflect the population in the geographic region, while preserving some aspects of the geographic location. There are several cartogram algorithms [@ACTUC;@CBATCC]; each involves shifting the boundaries of geographic units, using the value of the statistic to increase or decrease the area taken by the geographic unit on the map. The changes to the boundaries result in cartograms that accurately communicate population by map area for each of the geographic units but can result in losing the familiar geographic information. For Australia, the transformations warp the country so that it is no longer recognisable (see @KCR for details).

<!-- Other cartograms -->
Alternative algorithms make various trade-offs between familiar shapes and representation of geographic units. The non-contiguous cartogram method [@NAC] keeps the shapes of geographic units intact, and changes the size of the shape. This method disconnects areas creating empty space on the display losing the continuity of the spatial display of the statistic. The Dorling cartogram [@ACTUC] represents each unit as a circle, sized according to the value of the statistic. The neighbour relationships are mostly maintained by how the circles touch. A similar approach was pioneered by @RSCW, using rectangles that tile to align borders of neighbours [@CDWCS]. There have been thorough reviews of the array of methods, as suitable for cancer atlas displays [e.g. @KCR;@BCM], and experiments demonstrating cartograms to be more effective than choropleth maps [@KFIF].

<!-- Hexagon tile map -->
The hexagon tile map algorithm, automatically matches spatial regions to their nearest hexagon tile, from a grid of tiles. It has the effect of spreading out the inner city areas while maintaining the spatial locations or regions in remote areas. The algorithm is available in the R package, sugarbag [@sugarbag].  @fig-thyroid shows the hexagon tile map, where the map is coloured from low incidence (blue) to high (red). The inner city areas have expanded, making it possible to see the cancer incidence in the small, densely populated areas. Remote regions are represented by isolated hexagons, which is not ideal, but maintains the spatial location of these data values. It is of interest to know how well the spatial distribution patterns are seen from this display, in comparison to how they are seen from the choropleth map.

Hexagon displays are growing in popularity. Two media outlets used variations of the hexagon displays to communicate the 2025 Australian federal election results [@abc-election2025;@guardian-election2025]. Both are effective, but have inadequacies. The Guardian preserves geography and allows inner city results to be seen but the overall sense of the result is skewed because the large rural areas dominate the display. The ABC's contiguous hexagon tile map gives the correct sense of the final results but loses the shape of Australia, and some hexagons are far from their true location.

## Visual Inference

In order to assess the effectiveness of the hexagon tile map, the lineup protocol [@BCHLLSW09;@GIIV] from visual inference procedures is employed. The approach mirrors classical statistical inference. The procedures for doing a power comparison of competing plot design, outlined in @GTPCCD, are followed. It is the only current human subjects testing protocol which quantitatively compares plot designs on the basis of detection of structure relative to null distributions [@VCH;@VanderPlas2021Designing]. The premise for comparing two designs is that the only difference between the two lineups is the plot design, and hence difference in detection rate and time to detect is due to the effectiveness of the plot design for differentiating between data plot and null plots. The protocol has been used to quantitatively test plot designs numerous studies [e.g. @LHC;@VH2016;@KTV;@RS2021].

In classical statistical inference hypothesis testing is conducted by comparing the value of a test statistic on a standard reference distribution, computed assuming the null hypothesis is true. If the value is extreme,  the null hypothesis is rejected, because the test statistic value is unlikely to have been so extreme if it was true. In the lineup protocol, the plot plays the role of the test statistic, and the data plot is embedded in a field of null plots. Defining the plot using a grammar of graphics [@ggplot2] makes it a functional mapping of the variables and thus, it can be considered to be a statistic. With the same data, two different plots can be considered to be competing statistics, one possibly a more powerful statistic than the other. 

Hypothesis testing with the lineup protocol requires human evaluation. The human judge is required to identify the most different plot among the field of plots. If this corresponds to the data plot -- the test statistic -- the null hypothesis is rejected. It means that the data plot is extreme relative to the reference distribution of null plots. 

The null hypothesis is explicitly provided by the grammatical plot description. For example, if a histogram is the map type being used, the null might be that the underlying distribution of the data is a Gaussian. Null data would be generated by simulating from a normal model, with the same mean and standard deviation as the data. In practice, the null hypothesis used is generic, such as *there is NO structure or a pattern in the plot*, and contrasted to an alternative that there is structure. 

The chance that an observer picks the data plot out of a lineup of size $m$ plots accidentally, if the null hypothesis is true is $1/m$. With $K$ observers, the probability of $k$ randomly choosing the data plot, roughly follows a binomial distribution with $p=1/m$. @fig-lineup shows a lineup of the hexagon tile map, of size $m=12$. Plot 3 is the data plot, and the remaining 11 are plots of null data. The supplementary materials contain all lineups used in the study, including the corresponding lineup to this one made using choropleth maps. 

```{r}
#| label: fig-lineup
#| fig-cap: "This lineup of twelve hexagon tile map displays contains one map with a real population related structure (location 3). The rest are null plots that contain only spatial dependence."
#| fig-height: 8
#| fig-width: 8
ggdraw() +
  draw_plot(rasterGrob(readPNG("figures/aus_cities_3_hex.png")))
```

In order to determine the effectiveness of a type of display, this probability is less relevant than the overall proportion of observers who pick the data plot, $k/K$. The power of the test statistic (data plot) is provided by this proportion. Power in a statistical sense is the ability of the statistic to *produce a rejection* of the null hypothesis, if it is indeed *not true*. With the same data plotted using two different displays, the display with the highest proportion of people who choose the data plot would be considered to be the most powerful statistic. 

There are several practical considerations when deploying the lineup protocol: (1) determining the appropriate null distribution to compute null samples, (2) employing independent observers to conduct the evaluations, (3) varying location of the data plot in a lineup, (4) how many null sets to include in the lineup, (5) construction of all lineups in the experiment (see @VRCH), (6) questions presented to participants to solicit evaluations, in addition to the usual experimental design issues. These are described in detail in the next section.

# Methodology {#sec-methodology}

This study aims to answer two key questions around the presentation of spatial distributions:

1. Are spatial disease trends that impact highly populated small areas detected with higher accuracy, when viewed in a hexagon tile map?
2. Are people faster in detecting spatial disease trends that impact highly populated small areas when using a hexagon tile map?

Additional considerations when completing this experimental task included the difficulty experienced by participants and the certainty they had in their decision.

Australia is used for the study, with Statistical Area 3 (SA3) [@abs2016] as the geographic units. The results should apply broadly to any other geographic areas of interest, if there are large differences in area and population size. 

## Experimental factors

The primary factor in the experiment is the map type. The secondary factor is a trend model. Three trend models were developed: one mirroring a large spatial trend for which the choropleth map would be expected to do well, and two with differing levels of inner city hot spots. These latter two reflect the structure seen in the thyroid cancer incidence data (@fig-thyroid). This produces six treatment levels:

  - Map type: *Choropleth, Hexagon tile*
  - Trend: 
  
      - *NW-SE*: Large spatial trend running diagonally across Australia
      - *Three Cities*: Locations in three population centres
      - *All Cities*: Locations in all state and territory capitals

Data is generated for each of the trend models, with four replicates, and each displayed both as a choropleth map and as a hexagon tile map, which yields 12 data sets, and 24 data plots. This set of displays is divided in half, providing two sets of 12 displays, Group A and Group B. Participants were randomly allocated to Group A or B. Participants saw a data set only once, either as a choropleth map or as a hexagon tile map. @fig-exp-design summarises the design and the allocation of the displays.


```{r}
#| label: fig-exp-design
#| results: "asis" 
#| fig-width: 6 
#| fig-height: 4
#| out-width: 100%
#| fig-cap: "The experimental design used in the study. Participants are allocated to group A or B, to evaluate either the choropleth map or hexagon tile map lineup of each simulated data set. The text 'loc' refers to the location of the data plot in the lineup."

expt_design <- d |>
  count(group, trend, location, type, replicate)

ggplot(expt_design, ) +
  geom_tile(aes(x=group, y=1, fill=type)) +
  geom_text(aes(x=group, y=1, label = paste("loc:", location))) + 
  facet_grid(replicate~trend, axes = "all", labeller = labeller(replicate = label_both, trend = label_both)) +
  ylab("") +
  scale_fill_manual("", values = type_colors) +
  theme_minimal() +
  theme(axis.text.y = element_blank(),
        axis.ticks = element_blank())
```

## Generating null data

Null data needs to be data with no (interesting) structure. In most scenarios, permutation is the main approach for generating null plots. It is used to break association between variables, while maintaining marginal distributions. This is too simple for spatial data. In spatial data, a key feature is the spatial dependence or smoothness over the landscape. To do something simple, like permute the values relative to the geographic location would produce null plots which are too chaotic, and the data plot will be recognisable for its smoothness rather than any structure of interest. 

For spatial data, null data is stationary data, where the mean, variance and spatial dependence are constant over the geographic units. Stationary data is specified by a variogram model [@POG]. Simulating from a variogram model, where the spatial dependence is specified, generates the stationary spatial data used for the null plots.  The parameters for the Gaussian model were sill=1, range=0.3 with the variance generated by a standard normal distribution. 

The R package `gstat` [@gstat] was used to simulate 144 null sets, 12 data sets for each plot in a lineup, and 12 sets for 12 lineups. Simulating spatial dependence is difficult as discussed by @BDMSTW as a blockage for using the lineup protocol for testing map displays. Because the result from `gstat` was inadequate to mirror the spatial dependence patterns results in the @atlas, each null set was further smoothed. This was done by averaging a small number of spatial neighbours, approximating the methods described in @atlas-methods. 

```{r eval=FALSE, echo=FALSE}
# This is example code illustrating the null data generation
var.g.dummy <- gstat(formula = z ~ 1, 
                     locations = ~ longitude + latitude, 
                     dummy = T, beta = 1, model = vgm(psill = 1, model = "Gau", range = 0.3),
                     nmax = 12)

spatial_smoother <- function(area_number, 
                             values_vector, 
                             area_weight = 0.5, 
                             neighbours_list){
  
  stopifnot( area_weight >= 0 && area_weight <= 1)
  # List of the neighbours
  neighbours <- as.vector(neighbours_list[[area_number]])
  # Remove the current area
  neighbours <- neighbours[!neighbours == area_number]
  if ((length(values_vector[neighbours]))==0){
    smoothed_value <- values_vector[area_number]
  } else {
    # Weighted value: area value and neighbours
    ave_of_neighbours <- mean(values_vector[neighbours], na.rm = TRUE)
    smoothed_value <- (area_weight)*values_vector[area_number] + (1-area_weight)*ave_of_neighbours
  }
  return(smoothed_value)
}

var.sim1 <- predict(var.g.dummy, newdata = sa3_centroids, nsim = 12) |> 
  left_join(sa3_centroids, ., by=c("longitude", "latitude"))

sa3_sims1_1 <- as_tibble(var.sim1) |> 
  mutate_at(sims, ~map_dbl(1:nrow(sa3), spatial_smoother, 
                           values_vector = ., area_weight = 0.5, neighbours_list = sa3_neighbours))


```

## Generating lineups 

<!-- Discuss simulating the trend data -->
For each trend model, four real data displays were created by manipulating the centroid values of each of the SA3 geographic units. Each trend model is motivated by patterns observed in spatial data: North West to South East (NW-SE) is a basic spatial trend across the entire country, Three Cities is the existence of clusters of high values, and All Cities is also clusters, but more of them. We would expect that clusters pattern to be more visible with a hexagon tile map but the large spatial trend to be more visible in the choropleth map. 

The NW-SE distribution was created using a linear equation of the centroid longitude and latitude values. The All Cities trend model was created using the distance from the centroid of each geographic unit to the closest capital city in Australia, calculated when creating the hexagon tile map produced by the sugarbag [@sugarbag] package. Two-thirds of SA3s (201/336) were considered greater capital city areas, the values of these areas were increased to create red clusters. The amount was chosen to make clusters around the cities visible, even in the choropleth map with careful inspection. A similar selection process was applied to the Three Cities' trend model. However, for each of the four replicates for the Three Cities trend, a random sample of capital cities was taken from Sydney, Brisbane, Melbourne, Adelaide, Perth, and Hobart. Only values of the areas nearest to the three cities were increased to create clusters.


<!-- Location of data plot -->

One of the plot locations (1-20) is chosen to embed the data plot, in each of the four replicates, for the three trend models. These locations were chosen by random sampling. Using random locations reduces the chance that participants might deduce the location coincidentally. Locations 1, 7, 10 and 11 were not in the sample. @YMCCSG used the lineup protocol for a genomics study and similarly varied the the location of the data plot in replicates of treatments. Their results demonstrated that the actual location of the data plot didn't affect performance. So we don't expect that the location affects results but randomising locations among different lineups is to guard against participants expecting the data plot to be in a particular location.

The lineup locations were the same for both map types, because each set of lineup data was used to produce a choropleth map lineup and hexagon tile map lineup. This ensures that performance on the two map types can be directly compared.  Lineups were grouped into A or B, so that a participant saw only one version. Participants were assigned to group A or B, randomly, and thus evaluated either the choropleth map or the hexagon tile map lineup. Because there were four replicates of each lineup, each participant evaluated two choropleth map and two hexagon tile map lineups, for each trend model. This design is illustrated in @fig-exp-design.

<!-- Scaling data within a lineup -->

For each of the 144 individual maps, the values for each geographic area were rescaled to create a similar colour scale from deep blue to dark red within each map.
This meant at least one geographic unit was coloured dark blue, and at least one was red, in every map display of every lineup.

For the geographic NW-SE distribution, this resulted in the smallest values of the trend model (blue) occurring in Western Australia, the North West of Australia, and the largest values of the trend model (red) occurring in the South East. This resulted in Tasmania being coloured completely red. For the other two trend types, clusters localised in the cities appeared more red than the rest of Australia.


## Web application to collect responses

The taipan [@taipan] package for R was used to create the survey web application. 
This structure was altered to collect responses regarding participants' demographics and their survey responses.
The survey app contained three tabs. Participants were first asked for their demographics, their unique identifier and their consent to the responses being used for analysis. The demographics collected included participants' preferred pronoun, the highest level of education achieved, their age range and whether they had lived in Australia.

After submitting these responses, the survey application switched to the tab of lineups and associated questions. This allowed participants to easily move through the twelve displays and provide their choice, reason for their choice, and level of certainty. 

When participants completed the twelve evaluations the survey application triggered a data analysis script. This created a data set with one row per evaluation. Containing the responses to the three questions. The script also added the title of the image, which indicated the type of map display, the type of distribution hidden in the lineup, and the location of the data plot. It also calculated the time taken by participant to view each lineup.

Each participant used the internet to access the survey, and data was transferred by secure link from the web app to a Google sheet using the `googlesheets` package tools [@sheets].

## Participants

Participants were recruited from the Figure Eight crowd-sourcing platform [@figeight] to evaluate lineups.
The lineup protocol expects that the participants are uninvolved judges with no prior knowledge of the data, to avoid inadvertently affecting results. Potential participants needed to have achieved level 2 or level 3 from prior work on the platform, ensuring only participants with a good record on prior tasks could provide evaluations. All participants were at least 18 years old.

Participants were allocated to either group A or group B when they proceeded to the survey web application. There were 92 participants involved in the study. All participants read introductory materials, and were provided with some training using using three simple lineups, to orient them to the evaluation task. All participants who completed the task were compensated $AUD5 for their time, via the Figure Eight payment system.

A pilot study was conducted in the working group of the Econometrics and Business Statistics Department of Monash University. This allowed us to estimate the effect size, and thus decide on number of participants to collect responses from.

## Data collection

Each participant answered demographic questions and provided consent before evaluating the lineups.

Demographics were collected regarding the study participants:

 - Gender (female / male / other),
 - Education level achieved (high school / bachelors / masters / doctorate / other),
 - Age range (18-24 / 25-34 / 35-44 / 45-54 / 55+ / other)
 - Lived at least for one year in Australia (Yes / No )

Participants then moved to the evaluation phase. The set of images differed for Group A and Group B. After being allocated to a group, each individual was shown the 12 lineups in randomised order, and asked to report their responses to these three items:

 - **Plot choice**: the number of the plot that they deemed to be most different from the others.
 - **Reason**: one of "Clusters of colour", "Colour trend across the areas", "Big differences between neighbouring areas", "All areas have similar colours" or "None of these reasons". Note providing restricted list of reasons rather than free text encourages a response because it is easy. The list needs to contain the primary expected reasons and other potential reasons need to be added so that it does not bias the participants' behaviour.
 - **Certainty**: how certain that their choice is different from the others, on a scale of 1-5.


## Analysis

### Data Cleaning

Data is checked to ensure that survey responses collected for each participants were only included once. Technically it is possible to submit results more than once if the submit button is clicked multiple times in short sequence. Participants who did not finish the evaluation of all lineups or clicked through without providing their evaluation are removed. 

### Descriptive statistics

Basic descriptive statistics were computed for the different experimental treatments. Basic plots summarising detection rates by map type and trend model type, and feedback and demographic variables against the different experimental design elements are provided.

### Modelling

The likelihood of detecting the data plot in the lineup can be modelled using a linear mixed effects model. The R `glmer()` function in the `lme4` [@lme4] package implements generalised linear mixed effect models. The model used includes the two main effects map type and trend model, which gives the fixed effects model to be:

$$
\hat{y}_{ijk} \sim Bernoulli(p_{ijk})
$$
with

$$
\text{logit}(p_{ijk}) = \mu_i + \tau_j + \delta_k + (\tau \delta)_{jk}
$$

where $y_{ijk} = 0, 1$ represents whether subject $i$ detected the data plot (1) or did not (0), $\mu_i, ~i=1, \dots n$ is the subject-specific random intercept, $n$ is the number of subjects, $\tau_j, ~j=1,2$ is the map type effect, $\delta_k, ~k=1,2,3$ is the trend model effect. The interaction between map type and trend model allows for any map type effect to differ between trend models. As each participant provides results from 12 lineups, this model can account for each individual participants' abilities with the subject-specific random intercept. 

# Results {#sec-results}

A total of `r n_all_evals` responses were collected from `r n_all_contributors` participants. A small number of participants, `r n_all_contributors-n_contributors`,  were removed because they did not provide at least 11 responses, or left more than 3 at the default value of 0. These are participants that stopped early or clicked through without doing the evaluation. Set A was evaluated by `r n_AB$n[1]` participants, and `r n_AB$n[2]` evaluated set B. This resulted in `r n_evals` evaluations, corresponding to `r n_contributors` subjects, each evaluating 12 lineups, that were analysed on accuracy and speed. The certainty and reasons of subjects in their answers is also examined. 

## Accuracy

@fig-detect-compare displays the average detection rates for the two types of plot separately for each trend model. Each trend model was tested using four repetitions, evaluations on the same data set were seen as either choropleth maps or hexagon tile maps by each group as specified in @fig-exp-design; the detection rates for each display are connected by a line segment. The Three Cities and All Cities trend models shown in the hexagon tile map allowed viewers to detect the data plot substantially more often than the choropleth map counterparts. One replicate for the All Cities group had similar detection rates for both map types - the rate of detection using the choropleth map was much higher than other replicates. Surprisingly, participants could also detect the gradual spatial trend in the NW-SE group from the hexagon tile map. We expected that the choropleth map would be superior for the type of spatial pattern, but the data suggests the hexagon tile map performs slightly better, or equally as well.

```{r}
#| label: fig-detect-compare
#| fig-cap: "The detection rates achieved by participants are contrasted when viewing the four replicates of the three trend models. Each point shows the probability of detection for the lineup display, the facets separate the trend models hidden in the lineup. The points for the same data set shown in a choroleth or hexagon tile map display are linked to show the difference in the detection rate."
#| fig-height: 4
#| fig-width: 6
#| out-width: 100%
# Detectability rate for each lineup (image)
d_smry <- d |> group_by(trend, type, replicate) |>
  # pdetect measures the aggregated accuracy of the choices
  summarise(pdetect = length(detect[detect == 1])/length(detect)) |>
  ungroup()

# Numerical summary
diffs <- d_smry |> spread(type, pdetect) |>
  mutate(dif = `Hex.` - `Choro.`)

# Plot summary
ggplot(d_smry, aes(x = type, y = pdetect, color = trend)) +
  geom_point(size = 2) +  
  geom_line(size = 1, aes(group = replicate)) +  
  facet_wrap(~trend) +
  scale_color_manual(values = trend_colors) +
  xlab("") +
  ylab("Detection rate") + 
  ylim(0,1) +
  guides(scale = "none") +
  theme(legend.position = "none")
```

```{r}
#| eval: false
# Check detection rate across groups
d |> group_by(group) |>
    # pdetect measures the aggregated accuracy of the choices
    summarise(pdetect = length(detect[detect == 1])/length(detect)) |>
    ungroup()
```

```{r}
#| label: tbl-detect-glmer1
#| tbl-cap: "Parameter estimates of the fitted model fit for  detection rate. All terms are statistically significant  ($^{**}=0.01$, $^{***}=0.001$)."
# Mixed effects models
detect_fit <- glmer(detect ~ type*trend + (1|contributor), 
              family = binomial, data = d)

glmer_terms <- c("Intercept", "Hex.", "Three Cities", "All Cities",
  "Hex:Three Cities", "Hex:All Cities")

detection_rates <- tidy(detect_fit) |>
  mutate(detection_rates = round(exp(estimate)/(1+exp(estimate)),2)) |>
  select(term, estimate, detection_rates) |> pull(detection_rates)

detect_fit_smry <- summary(detect_fit)

tidy(detect_fit) |>
  mutate_at(.vars = c("estimate", "std.error"), round, 2) |> 
  mutate(p.value = round(p.value, digits=2)) |> 
  rowwise() |>
  mutate(sig = case_when(
  p.value <= 0.001 ~ "$^{***}$",
  p.value <= 0.01 ~  "$^{**}$",
  p.value <= 0.05 ~  "$^{*}$",
  p.value <= 0.01 ~  "$^{.}$",
  TRUE ~ "$^{ }$")) |>
  ungroup() |> 
  filter(!is.na(std.error)) |>
  mutate(term = glmer_terms) |> 
  select(Term = term, 
    Est. = estimate,
    `Std. Err.` = std.error, 
    `P-val.` = p.value, 
    Sig. = sig) |> 
  knitr::kable(format = "latex", escape = FALSE, align= "rrlrr", 
    booktabs = T, linesep = c("", "\\addlinespace", "", "\\addlinespace", ""))
```

```{r}
#| label: tbl-detect-prop
#| tbl-cap: "Model estimates for the proportion of detection in each of the trend models (standard error). Note that selecting the data plot by chance would produce a detection rate of 0.083, for each lineup."
# Proportions of detections, estimated from model
detect_props <- emmeans(detect_fit, specs = ~ type*trend, type = "response") |>
  as_tibble() |>
  select(type, trend, prob, SE) |>
  pivot_wider(names_from = trend, values_from = c(prob, SE)) |>
  pivot_longer(cols = `prob_All Cities`:`SE_NW-SE`, 
               names_to = "stat", values_to = "value") |>
  separate(stat, into = c("prop", "trend"), sep="_") |>
  pivot_wider(names_from = trend, values_from = value) 
detect_props <- detect_props |>
  mutate(`All Cities` = as.character(round(`All Cities`, 2)),
         `Three Cities` = as.character(round(`Three Cities`, 2)),
         `NW-SE` = as.character(round(`NW-SE`, 2))) |>
  mutate(type = as.character(type))
detect_props[2,1] <- ""
detect_props[4,1] <- ""
detect_props[2, 3] <- paste0("(", detect_props[2, 3], ")")
detect_props[4, 3] <- paste0("(", detect_props[4, 3], ")")
detect_props[2, 4] <- paste0("(", detect_props[2, 4], ")")
detect_props[4, 4] <- paste0("(", detect_props[4, 4], ")")
detect_props[2, 5] <- paste0("(", detect_props[2, 5], ")")
detect_props[4, 5] <- paste0("(", detect_props[4, 5], ")")
detect_props |>
  select(type, `All Cities`, 
                  `Three Cities`, `NW-SE`) |>
  knitr::kable(format = "latex", escape = FALSE, align= "lccc", 
    booktabs = T, 
    col.names = c("Map type", "All Cities", 
                  "Three Cities", "NW-SE"), 
    linesep = c("", "\\addlinespace", "", "\\addlinespace", ""))
```

@tbl-detect-glmer1 presents a summary of the generalised linear mixed effects model, testing the effect of map type and trend model on the detection rate. The results support the summary from @fig-detect-compare. Overall, the hexagon tile map performs marginally better than the choropleth map for all trend models, and with differing magnitudes of effects. The subject-specific random intercepts have mean `r round(detect_fit_smry$varcor$contributor[[1]], 2)` and standard deviation `r round(attr(detect_fit_smry$varcor$contributor, "stddev")[[1]], 2)`.

The estimated detection proportion from the model fit, computed using the `emmeans` package [@Lenth2025] are shown in @tbl-detect-prop. For the All Cities trend participants were about three times more likely to detect the cluster pattern with the hexagon tile map than the choropleth map. The Three Cities trend was practically not detectable in the choropleth map. The detection rates were more similar for the NW-SE trend, but slightly higher for the hexagon tile map, which was a surprise. Note that, these detection rates are all substantially higher than chance, except for the choropleth map on the Three Cities. For a single evaluation, the detection rate of the data plot selected by chance is $1/12=0.083$ because the lineups used in this experiment had 12 plots. The choice of 12 plots in the lineups instead of the usual 20, which would have produced the by chance detection rate of 0.05, is because reading a map is relatively complex, and pilot studies suggested that 12 was a reasonable cognitive load but 20 was not. When designing an experiment like this it is important to produce lineups that strike a balance between simple and hard, so that there is a chance of discovering the effect of interest. This experiment has managed to do this extremely well, which is a result of pilot studies, careful null data generation, and power calculations to determine appropriate sample size.



```{r}
#| label: fig-beeswarm
#| fig-cap: "The distribution of the time taken (seconds) to submit a response for each combination of trend, whether the data plot was detected, and type of display, shown using a median value and horizontally jittered dotplots. There are only small differences in time taken between map types. Some participants take under a second per evaluation, and some take as much as 60 seconds, but this occurs with detection and non-detection."
#| fig-height: 4
#| fig-width: 6
#| out-width: 100%
s <- d |> group_by(type, trend, detect_f) |>
  summarise(m=median(time_taken), 
            q1=quantile(time_taken, 0.25), 
            q3=quantile(time_taken, 0.75),
            s=sd(time_taken),
            n=n()) |>
  mutate(lc = m - s*qt(0.975, n-1)/sqrt(n),
         uc = m + s*qt(0.975, n-1)/sqrt(n))
ggplot() + 
  geom_quasirandom(data=d, aes(x=type, y=time_taken, color=type), alpha=0.2) + 
  geom_point(data=s, aes(x=type, y=m, color=type), size=3) +
  scale_color_manual("", values = type_colors) +
  facet_grid(detect_f~trend) + 
  ylab("Time taken (seconds)") + xlab("") +
  theme_bw() +
  theme(legend.position="none")
```

```{r}
#| eval: false
# Check groups and demographics
d |> group_by(group) |>   
  summarise(m=mean(time_taken), 
            s=sd(time_taken))
d |> group_by(gender) |>   
  summarise(m=mean(time_taken), 
            s=sd(time_taken))
d |> group_by(age) |>   
  summarise(m=mean(time_taken), 
            s=sd(time_taken))
d |> group_by(education) |>   
  summarise(m=mean(time_taken), 
            s=sd(time_taken))

```

```{r}
# Check time difference between default choice
d_zeros <- d |> mutate(zeros = if_else(choice == 0, 0, 1)) |>
  group_by(zeros) |>   
  summarise(m=median(time_taken), 
            mn=min(time_taken),
            mx=max(time_taken),
            q1=quantile(time_taken, 0.25), 
            q3=quantile(time_taken, 0.75),
            n=n())

d_zeros_detect <- d |> mutate(zeros = if_else(choice == 0, 0, 1)) |>
  group_by(zeros, detect_f) |>   
  summarise(m=median(time_taken), 
            mn=min(time_taken),
            mx=max(time_taken),
            q1=quantile(time_taken, 0.25), 
            q3=quantile(time_taken, 0.75),
            n=n())
# Summarise across subjects
contributor_smry <- d |> group_by(contributor) |>   
  summarise(m_d=mean(detect), 
            s_d=sd(detect),
            m_t=mean(time_taken), 
            s_t=sd(time_taken)) 
```

```{r}
#| eval: false
ggplot(contributor_smry, aes(m_t, m_d)) +
  geom_point() +
  ylab("Detection rate") +
  xlab("Time taken") +
  xlim(c(0, 45)) +
  theme(aspect.ratio = 1)
ggplot(contributor_smry, aes(m_t, s_t)) +
  geom_point() +
  xlab("Average") +
  ylab("SD") +
  theme(aspect.ratio = 1)
ggplot(contributor_smry, aes(m_d, s_d)) +
  geom_point() +
  xlab("Average") +
  ylab("SD") +
  theme(aspect.ratio = 1)
```

## Speed

@fig-beeswarm shows horizontally jittered dot plots to contrast the time taken by participants to evaluate each lineup faceted by map type and trend model. Each dot is an evaluation. The time taken to complete an evaluation ranged from fractions of a second to 60 seconds. The average time taken for type of display is shown as a large coloured dot on each plot, and show there is little difference in the average time taken to read a lineup made with either a choropleth map or hexagon tile map. 

That some evaluations occurred within milliseconds is a little surprising. Investigating whether this was related the `r d_zeros$n[1]` of `r d_zeros$n[1]+d_zeros$n[2]` evaluations where participants left the default choice of 0, and we find it is not; most of these people took the routine time to examine, and then left it at the default suggesting that they just could not pick one as different. This is the same as a non-detect. On a per participant basis, the average time per lineup over the 12 evaluations ranged between `r round(min(contributor_smry$m_t), 2)` and `r round(max(contributor_smry$m_t), 2)` seconds. The correlation between average detection rate and time taken across subjects `r round(cor(contributor_smry$m_d, contributor_smry$m_t), 2)` which is weakly positive. This is similar to what we have found in other studies, some subjects are especially fast and accurate in visual evaluation, and conversely some subjects are quite slow but inaccurate.


```{r}
#| label: fig-certainty 
#| fig-cap: "The distribution of certainty chosen by participants when viewing hexagon tile map or choropleth map displays, shown as centered bar plots, faceted by the trend model and whether the plot was detected or not. Participants tended to choose higher certainty when evaluating a choropleth map, on average, particularly when the data plot was not detected."
#| fig-height: 5
#| fig-width: 10
#| out-width: 100%
d <- d |> 
  mutate(certainty = as_factor(certainty)) |> 
  mutate(replicate_f = as_factor(replicate)) 
 
d_tbl <- d |> 
  mutate(Detected = factor(detect_f, 
    levels = c("Detected? Yes", "Detected? No"), 
    labels = c("Detected? Yes", "Detected? No"))) |>
  mutate(type = fct_recode(type, "choropleth" = "Choro.", "hexagon tile" = "Hex.")) |>
  mutate(certainty_f = fct_recode(certainty, "Very uncertain"="1", 
                                "Uncertain"="2", 
                                "Neutral"="3",
                                "Certain"="4",
                                "Very certain"="5")) |>
  select(contributor, replicate, certainty_f, type, Detected, trend) |>
  pivot_wider(names_from=type, values_from=certainty_f)
gglikert(d_tbl, include=choropleth:`hexagon tile`,
         facet_rows=vars(Detected), facet_cols=vars(trend),
         add_labels=FALSE, add_totals=FALSE) +
  scale_fill_brewer("", palette="PiYG")
```


## Certainty

Participants provided their level of certainty regarding their choice using a five point scale. Unlike the accuracy and speed of responses that were derived during the data processing phase, this was a subjective assessment by the participant prompted by the question: "How certain are you about your choice?". @fig-certainty shows centred bar charts summarising how participants reported their certainty with their decision. The sub-plots show each combination of trend models and whether the data plot was detected or not. Colour indicates the certainty in their decision. Participants tended to be slightly more certain when shown the choropleth map when the trend model was "All cities", and when the data plot was not detected for all three trend types. 

## Reason

@tbl-reason summarises the reasons that participants gave for their choices: "clusters" = "Clusters of colour", "trend" = "Colour trend across the areas", "consistent" = "All areas have similar colours", "hotspots" = "Big differences between neighbouring areas", "none" = "None of these reasons". These proportions are computed separately for each trend, map type and whether the participant detected the data plot. With All Cities and Three Cities, when correct, participants tended to select 'consistent' with the choropleth map, and 'clusters' with the hexagon tile map. With the NW-SE trend, 'trend' was primarily selected for the choropleth map, but 'clusters' was the primary reason for the hexagon tile map. The primary reasons are similar when the participant did not detect the data plot.

The results when the data plot was detected are as expected, but that they are similar to the not detected group is interesting. It suggests that with the choropleth map people are trying to read contiguous patterns, while the hexagon tile map is being read for pockets of differences. This may be due the hexagon tile map being non-contiguous. 


```{r}
#| label: tbl-reason
#| tbl-cap: "Proportion of reasons provided by participants for their plot choice, broken down by Trend, Map Type, and data plot detection. The primary reason when participants were evaluating the choropleth map was 'consistent' or 'trend', but for the hexagon tile map it was 'clusters', when they detected the data plot."
# Qualitative analysis of reason
reasons_smry <- d |> 
  mutate(reason = ifelse(reason =="0.0", "no reason", reason)) |> 
  mutate(Detected = ifelse(detect_f == "Detected? Yes", 
                           "Yes", "No"),
    Trend = trend) |> 
  group_by(Trend, Detected, type) |> 
  count(reason) |>
  ungroup() |>
  group_by(Trend, Detected, type) |>
  mutate(prop = n/sum(n)) |> 
  ungroup() |>
  select(Trend, Detected, type, reason, prop) |>
  mutate(prop = round(prop, 2)) |>
  pivot_wider(names_from = reason, 
              values_from = prop, 
              values_fill = 0) |>
  select(Trend, Detected, type, clusters, trend, consistent, hotspots, `no reason`)
  
reasons_smry |>  
  arrange(desc(Detected), Trend, type) |>
  knitr::kable(format = "latex", booktabs = TRUE,
               col.names = c("Trend", "Detect", "Type", 
                             "clusters", "trend", "consistent",
                             "hotspots", "none"),
                 align = "lllrrrrr",
    linesep = c("", "\\addlinespace", "", "\\addlinespace","", "\\addlinespace","", "\\addlinespace","", "\\addlinespace","")) 
```

## Participant demographics

Of the `r n_contributors` participants, `r n_gender$n[1]` were male, and `r n_gender$n[2]` female. Most participants (`r n_educ$n[1]`) had a Bachelors degree, `r n_educ$n[3]` had a Masters degree, and the remaining `r n_educ$n[2]` had high school diplomas. The age distribution was `r paste(n_age$n[1:5], collapse=", ")` for age groups 18-24, 25-34, 35-44, 45-54, 55+, with `r n_age$n[6]` preferring not to answer. Only `r n_aus$n[2]` reported having lived in Australia. Note that, the purpose of reporting these numbers is to illustrate the reasonable variety of demographic background of participants. However, `r n_contributors` observations is insufficient to include this demographic information in the model. @MHC (published in 2025 but conducted in 2012) showed that there is little difference in performance on lineup experiments between demographic groups. @VH2016 found that visual aptitude for reading data plots was associated with mathematical skills, but this study was done on statistical plots of data, not maps. Assessing mathematical ability requires substantially more data collection, and does not necessarily correlate with education level. 

Summary statistics (not included here, but available in the analysis code) show no differences in results between sets A and B in detection rate or time taken. Similarly, detection rates and time taken vary little across age, education and gender.


# Discussion

This study provides evidence that the hexagon tile map is superior to a choropleth map for communicating population statistics, for Australia. While the cartogram has been established as better than a choropleth map, cartograms do not work for the vast disparity between population density and geographic area in Australia. The hexagon tile map was developed to provide a possible solution, and this study demonstrates that it has potential. 

The R package `sugarbag` can be used to generate a hexagon tile map. It can be used for any spatial polygon data, so is applicable to other countries or geographic areas. 

One of the strengths but potential limitations of the hexagon tile map is that it is non-contiguous; large rural areas are represented by isolated hexagons. This is why we expected that the hexagon tile map might not work well to detect large-scale spatial trend ("NW-SE"). The primary reason for producing the non-contiguous display was to preserve geography sufficiently for the reader to easily recognise the location. This is a strength, and allows a map of the country to be drawn underneath the hexagons. It appears to not inhibit reading of the spatial distribution based on this experiment. However, there is considerable room for improving the algorithm and exploring some variations. These might include increasing the size of isolated hexagons, or collecting multiple hexagons together. 

The manner in which hexagons are exploded out from the city centres is another direction of research. Ideally, the location of the hexagons should be close to their original location but this is hard to control and measure. The current algorithm works sequentially to place hexagons, radially from a provided centre. There are likely better optimisation procedures that could improve the layout. For reading the spatial distribution, this is less important, but if the hexagon tile map is provided to users as an interactive tool, they will want to locate themselves in the plot. If the hexagon is not close to the true location it could be disconcerting.

This experiment focused on comparing a new display, the hexagon tile map, against the standard display, choropleth map. There are other options that could have been included in the study, such as the use of insets of dense population areas along with the choropleth map, or the use of interactive graphics linking statistical charts with the choropleth map. Keeping the scope of the study small was important to understand whether it was reasonable to recommend use of the hexagon tile map. Although we only tested on the Australian geography, the results should hold for other regions that have similarly disparities between population size and geographic size. 

We would recommend doing follow-up studies that allow deeper understanding of how the different displays are read. For example, an eye-tracking experiment could help to understand the differences in how people read the choropleth map and the hexagon tile map as indicated by the different reasons given. @ZCHMR is an example of such an experiment where the manner in which people read lineups was examined.

<!--We expected that the choropleth map would be superior for communicating the spatial pattern of geographic trends (NW-SE). The data suggest that the participants perform slightly better or equally as well for each replicate in each trend model across the two displays. Table II shows that the difference in the mean detection rate for the two trend models was 0.10.

Relating to @fig-detect-compare, and the model results, surprisingly the difference between map types for the geographic distribution was significant at the 0.05 level, even though the effect difference is small. It also showed that the hexagon tile map display performs marginally better than the choropleth for all trend models. -->

While the significance of the difference in detection was the key focus of this experiment, the secondary focus was the time taken by participants. It was expected that the participants may take longer to consider the hexagon tile map distribution but would be able to detect the data plot in the lineup.
The bimodal distributions seen in @fig-beeswarm showed very little difference in the median evaluation times. As the maximum time of all of the distributions approached 60 seconds it cannot be said that the participants took longer to evaluate the hexagon tile map displays. 

The responses to the questions asked of participants included the reason for their choice and the certainty around their choice.
@fig-certainty showed generally higher levels of certainty were chosen by participants when looking at the population distributions in a choropleth map display suggesting that they were more confident. This was especially the pattern when the data plot was not detected. The high levels of the mid-range value of "Neutral" could indicate that the participants did not want to provide a response, as this was the default value. 

The colour scaling applied in Three cities and All cities displays resulted in the rural areas of the real data plot appearing more blue or yellow than the other plots in the lineups.
Due to the consistent colouring of rural areas in a choropleth map display, the choice "All areas have similar colours" was most common reason for a participants choice. The All Cities displays coloured the inner-city areas of all capital cities more red, this was observable to participants and explains the equal choice of the city clusters or rural colour consistency. 
Choosing "Clusters of colour" was expected when participants viewed the Hexagon tile map display of the All Cities and Three Cities distributions. It was unexpected that it was also the most common reason for the NW-SE hexagon tile map displays. 
Due to the spatial covariance introduced in the smoothing, groups of similarly coloured hexagons were present in all of the hexagon tile map displays. All Cities and Three Cities distributions of real data trends had distinctly different patterns or red inner-city areas, while some of the plots in each lineup may have shared similar features.


# Conclusion

The choropleth map display and the tessellated hexagon tile map have been contrasted using the lineup protocol. The hexagon tile map was significantly more effective for spotting a real population related data trend model hidden in a lineup.

The hexagon tile map display should be considered as an alternative visualisation method when communicating distributions that relate to the population across a set of geographic units. As an additional display to the familiar choropleth map, cancer atlas products may benefit from the opportunity to allow exploration via an alternative display. The spatial distributions used to test these displays were inspired by the real spatially smoothed estimates of the cancer burden on Australian communities. This technique may be useful for other population related distributions, such as other diseases, or election results or socioeconomic indicators.

The increasing population densities of capital cities despite large land area exacerbates the difference in the smallest and largest communities.
The population density structure of Australia can be considered similar to that of Canada, New Zealand and many other countries. Therefore, this display is not only relevant to Australia, but all nations or population distributions that experience densely populated cities separated by vast rural expanses.

# Acknowledgments {-}

The authors would like to thank the Australian Cancer Atlas team for discussions regarding alternative spatial visualisations, and Professor Kerrie Mengersen and Dr Earl Duncan for regular meetings filled with suggestions and comments. Mitchell O'Hara-Wild was a co-developer of the taipan [@taipan] R package for image tagging, used as the base for the web app constructed to collect participant evaluations of lineups. We are thankful for the NUMBATs (Non-Uniform Monash Business Analytics Team) for participating in the pilot study that helped to assess the experimental design and determine an appropriate sample size for the study. 

# Supplementary materials and reproducibility {-}

This document was written using quarto. This document contains the code to produce the summaries, plots and additional checks in the paper. All the code to reproduce the analysis, and do additional checks can be found on [GitHub](https://github.com/srkobakian/experiment/paper).
Supplementary materials have been included to discuss the survey procedures and the lineups that were used.
The full set of images can be found here, too. 

The supplementary material contains:

- Additional analysis of the experimental results
- Survey procedure including training materials for the participants
- 24 lineups as images, that were used in the experiment
- 12 data sets used to construct the lineups

The analysis of the work was completed in R [@RCore] with the use of the following packages:

 - Document creation: quarto [@Allaire_Quarto_2025], anzjs template [@quarto-anzjs], knitr [@knitr].
 - Lineup creation: nullabor [@nullabor], gstat [@gstat].
 - Data analysis: tidyverse [@tidyverse], ggthemes [@ggthemes], RColorBrewer [@RColorBrewer].
 - Plots: ggplot2 [@ggplot2], cowplot [@cowplot], png [@png], ggbeeswarm [@ggbeeswarm], ggmosaic [@ggmosaic].
 - Modelling and summary presentation: lme4 [@lme4], kableExtra [@kableExtra].

# Ethics Declaration {-}

Ethics approval for the online survey was granted by QUTs Ethics Committee (Ethics Application Number: 1900000991). All applicants provided informed consent in line with QUT regulations prior to participating in this research.


